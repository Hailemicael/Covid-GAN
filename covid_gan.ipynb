{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.14",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 9986018,
          "sourceType": "datasetVersion",
          "datasetId": 6145426
        }
      ],
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hailemicael/Covid-GAN/blob/master/covid_gan.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip \"/content/images_1.zip\""
      ],
      "metadata": {
        "collapsed": true,
        "id": "XjvahqycACXP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Importing Libraries**"
      ],
      "metadata": {
        "id": "61dpUybX-4br"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision.utils import save_image, make_grid\n",
        "from PIL import Image\n",
        "from torch.utils.tensorboard import SummaryWriter"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "_91uiUhw2nWf"
      },
      "outputs": [],
      "execution_count": 6
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"GPU Available:\", torch.cuda.is_available())\n",
        "print(\"GPU Device Name:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"No GPU\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-22T21:49:42.968013Z",
          "iopub.execute_input": "2024-11-22T21:49:42.968397Z",
          "iopub.status.idle": "2024-11-22T21:49:46.272081Z",
          "shell.execute_reply.started": "2024-11-22T21:49:42.968360Z",
          "shell.execute_reply": "2024-11-22T21:49:46.270767Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sYE-SjwO2nWh",
        "outputId": "08d3c733-d98b-474c-aa7a-a312afb80cb1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU Available: True\n",
            "GPU Device Name: Tesla T4\n"
          ]
        }
      ],
      "execution_count": 7
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Dataset Loading**\n"
      ],
      "metadata": {
        "id": "xe-BMW1H_ViQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CovidDataset(Dataset):\n",
        "    def __init__(self, root_dir='/content/images', transform=None):\n",
        "        self.root_dir = root_dir\n",
        "        self.image_files = [f for f in os.listdir(root_dir) if f.endswith(('.png', '.jpg', '.jpeg'))]\n",
        "        self.transform = transform or transforms.Compose([\n",
        "            transforms.Grayscale(1),\n",
        "            transforms.Resize((128, 128)),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.5], [0.5])\n",
        "        ])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = os.path.join(self.root_dir, self.image_files[idx])\n",
        "        image = Image.open(img_path)\n",
        "        return self.transform(image)"
      ],
      "metadata": {
        "id": "0m8rjDyx_ULd"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(1, 64, 4, 2, 1),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Dropout2d(0.2),\n",
        "\n",
        "            nn.Conv2d(64, 128, 4, 2, 1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.LeakyReLU(0.2),\n",
        "\n",
        "            nn.Conv2d(128, 256, 4, 2, 1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.LeakyReLU(0.2),\n",
        "\n",
        "            nn.Conv2d(256, 512, 4, 2, 1),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.LeakyReLU(0.2),\n",
        "        )\n",
        "\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(512 * 8 * 8, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        return self.fc(x)\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, z_dim):\n",
        "        super().__init__()\n",
        "        self.fc = nn.Linear(z_dim, 512 * 8 * 8)\n",
        "\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.ConvTranspose2d(512, 256, 4, 2, 1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.ConvTranspose2d(256, 128, 4, 2, 1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.ConvTranspose2d(128, 64, 4, 2, 1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.ConvTranspose2d(64, 1, 4, 2, 1),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc(x)\n",
        "        x = x.view(-1, 512, 8, 8)\n",
        "        return self.conv(x)\n",
        "\n",
        "class CovidGAN:\n",
        "    def __init__(self, z_dim=100, lr=1e-4, batch_size=32):\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.z_dim = z_dim\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "        self.gen = Generator(z_dim).to(self.device)\n",
        "        self.disc = Discriminator().to(self.device)\n",
        "\n",
        "        self.opt_disc = optim.Adam(self.disc.parameters(), lr=lr, betas=(0.5, 0.999))\n",
        "        self.opt_gen = optim.Adam(self.gen.parameters(), lr=lr*1.5, betas=(0.5, 0.999))\n",
        "\n",
        "        self.criterion = nn.BCELoss()\n",
        "        self.writer = SummaryWriter('runs/covid_gan')\n",
        "\n",
        "        os.makedirs('generated_images', exist_ok=True)\n",
        "        os.makedirs('model_checkpoints', exist_ok=True)\n",
        "\n",
        "    def train(self, num_epochs=200):\n",
        "        dataset = CovidDataset()\n",
        "        dataloader = DataLoader(dataset, batch_size=self.batch_size, shuffle=True, num_workers=2)\n",
        "\n",
        "        fixed_noise = torch.randn(32, self.z_dim).to(self.device)\n",
        "\n",
        "        print(f\"Starting training on {self.device}\")\n",
        "        print(f\"Dataset size: {len(dataset)} images\")\n",
        "\n",
        "        step = 0\n",
        "        for epoch in range(num_epochs):\n",
        "            for batch_idx, real_images in enumerate(dataloader):\n",
        "                batch_size = real_images.size(0)\n",
        "                real_images = real_images.to(self.device)\n",
        "\n",
        "                # Train Discriminator\n",
        "                self.opt_disc.zero_grad()\n",
        "                label_real = torch.ones(batch_size, 1).to(self.device)\n",
        "                label_fake = torch.zeros(batch_size, 1).to(self.device)\n",
        "\n",
        "                output_real = self.disc(real_images)\n",
        "                d_loss_real = self.criterion(output_real, label_real)\n",
        "\n",
        "                noise = torch.randn(batch_size, self.z_dim).to(self.device)\n",
        "                fake_images = self.gen(noise)\n",
        "                output_fake = self.disc(fake_images.detach())\n",
        "                d_loss_fake = self.criterion(output_fake, label_fake)\n",
        "\n",
        "                d_loss = (d_loss_real + d_loss_fake) / 2\n",
        "                d_loss.backward()\n",
        "                self.opt_disc.step()\n",
        "\n",
        "                # Train Generator\n",
        "                self.opt_gen.zero_grad()\n",
        "                output_fake = self.disc(fake_images)\n",
        "                g_loss = self.criterion(output_fake, label_real)\n",
        "                g_loss.backward()\n",
        "                self.opt_gen.step()\n",
        "\n",
        "                if batch_idx % 10 == 0:\n",
        "                    print(f\"Epoch [{epoch}/{num_epochs}] Batch [{batch_idx}/{len(dataloader)}] \"\n",
        "                          f\"D_loss: {d_loss:.4f}, G_loss: {g_loss:.4f}\")\n",
        "\n",
        "                    self.writer.add_scalar(\"D_loss\", d_loss.item(), step)\n",
        "                    self.writer.add_scalar(\"G_loss\", g_loss.item(), step)\n",
        "\n",
        "                    with torch.no_grad():\n",
        "                        fake_samples = self.gen(fixed_noise)\n",
        "                        save_image(fake_samples, f\"generated_images/epoch_{epoch}_batch_{batch_idx}.png\",\n",
        "                                 normalize=True, nrow=8)\n",
        "\n",
        "                        self.writer.add_image(\"Generated Images\",\n",
        "                                            make_grid(fake_samples, normalize=True, nrow=8),\n",
        "                                            step)\n",
        "\n",
        "                step += 1\n",
        "\n",
        "            # Save model every epoch\n",
        "            torch.save({\n",
        "                'generator_state_dict': self.gen.state_dict(),\n",
        "                'discriminator_state_dict': self.disc.state_dict(),\n",
        "                'gen_optimizer_state_dict': self.opt_gen.state_dict(),\n",
        "                'disc_optimizer_state_dict': self.opt_disc.state_dict(),\n",
        "            }, f'model_checkpoints/covid_gan_epoch_{epoch}.pth')\n",
        "\n",
        "        self.writer.close()\n",
        "\n",
        "    def generate_samples(self, num_samples=16):\n",
        "        with torch.no_grad():\n",
        "            noise = torch.randn(num_samples, self.z_dim).to(self.device)\n",
        "            fake_images = self.gen(noise)\n",
        "            save_image(fake_images, \"generated_samples.png\", normalize=True, nrow=4)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    gan = CovidGAN()\n",
        "    gan.train(num_epochs=200)\n",
        "    gan.generate_samples()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-22T21:57:57.679716Z",
          "iopub.execute_input": "2024-11-22T21:57:57.679956Z",
          "iopub.status.idle": "2024-11-22T23:04:03.323870Z",
          "shell.execute_reply.started": "2024-11-22T21:57:57.679931Z",
          "shell.execute_reply": "2024-11-22T23:04:03.322482Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZR2-tqfi2nWi",
        "outputId": "6e2ffdb1-8ba6-4d44-d6a6-ba2dd8dd40fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training on cuda\n",
            "Dataset size: 3616 images\n",
            "Epoch [0/200] Batch [0/113] D_loss: 0.6740, G_loss: 1.1175\n",
            "Epoch [0/200] Batch [10/113] D_loss: 0.0611, G_loss: 3.5388\n",
            "Epoch [0/200] Batch [20/113] D_loss: 0.0465, G_loss: 3.9597\n",
            "Epoch [0/200] Batch [30/113] D_loss: 0.0582, G_loss: 5.5345\n",
            "Epoch [0/200] Batch [40/113] D_loss: 0.0241, G_loss: 6.2572\n",
            "Epoch [0/200] Batch [50/113] D_loss: 0.0181, G_loss: 6.2205\n",
            "Epoch [0/200] Batch [60/113] D_loss: 0.0149, G_loss: 6.3180\n",
            "Epoch [0/200] Batch [70/113] D_loss: 0.0102, G_loss: 6.3120\n",
            "Epoch [0/200] Batch [80/113] D_loss: 0.0658, G_loss: 6.5752\n",
            "Epoch [0/200] Batch [90/113] D_loss: 0.0011, G_loss: 7.3538\n",
            "Epoch [0/200] Batch [100/113] D_loss: 0.0098, G_loss: 7.3150\n",
            "Epoch [0/200] Batch [110/113] D_loss: 0.0212, G_loss: 6.4913\n",
            "Epoch [1/200] Batch [0/113] D_loss: 0.0015, G_loss: 8.5346\n",
            "Epoch [1/200] Batch [10/113] D_loss: 0.0014, G_loss: 7.3338\n",
            "Epoch [1/200] Batch [20/113] D_loss: 0.0047, G_loss: 7.4501\n",
            "Epoch [1/200] Batch [30/113] D_loss: 0.0076, G_loss: 7.1843\n",
            "Epoch [1/200] Batch [40/113] D_loss: 0.0015, G_loss: 7.9804\n",
            "Epoch [1/200] Batch [50/113] D_loss: 0.0071, G_loss: 7.2909\n",
            "Epoch [1/200] Batch [60/113] D_loss: 0.0009, G_loss: 8.3102\n",
            "Epoch [1/200] Batch [70/113] D_loss: 0.0004, G_loss: 10.5451\n",
            "Epoch [1/200] Batch [80/113] D_loss: 0.0005, G_loss: 13.8997\n",
            "Epoch [1/200] Batch [90/113] D_loss: 0.0945, G_loss: 16.0640\n",
            "Epoch [1/200] Batch [100/113] D_loss: 0.3883, G_loss: 20.8682\n",
            "Epoch [1/200] Batch [110/113] D_loss: 0.0069, G_loss: 8.9212\n",
            "Epoch [2/200] Batch [0/113] D_loss: 0.0185, G_loss: 9.4848\n",
            "Epoch [2/200] Batch [10/113] D_loss: 0.0335, G_loss: 7.7362\n",
            "Epoch [2/200] Batch [20/113] D_loss: 0.0108, G_loss: 5.1270\n",
            "Epoch [2/200] Batch [30/113] D_loss: 0.0149, G_loss: 5.4039\n",
            "Epoch [2/200] Batch [40/113] D_loss: 2.0501, G_loss: 17.5504\n",
            "Epoch [2/200] Batch [50/113] D_loss: 0.3376, G_loss: 7.7847\n",
            "Epoch [2/200] Batch [60/113] D_loss: 0.1948, G_loss: 2.2138\n",
            "Epoch [2/200] Batch [70/113] D_loss: 0.0815, G_loss: 2.4436\n",
            "Epoch [2/200] Batch [80/113] D_loss: 0.5761, G_loss: 4.5655\n",
            "Epoch [2/200] Batch [90/113] D_loss: 0.4935, G_loss: 4.4909\n",
            "Epoch [2/200] Batch [100/113] D_loss: 0.1380, G_loss: 4.6643\n",
            "Epoch [2/200] Batch [110/113] D_loss: 0.0278, G_loss: 5.5752\n",
            "Epoch [3/200] Batch [0/113] D_loss: 0.1242, G_loss: 1.4769\n",
            "Epoch [3/200] Batch [10/113] D_loss: 0.0886, G_loss: 4.1896\n",
            "Epoch [3/200] Batch [20/113] D_loss: 0.6420, G_loss: 2.6413\n",
            "Epoch [3/200] Batch [30/113] D_loss: 0.4919, G_loss: 1.6770\n",
            "Epoch [3/200] Batch [40/113] D_loss: 0.2532, G_loss: 1.0979\n",
            "Epoch [3/200] Batch [50/113] D_loss: 0.0977, G_loss: 1.6316\n",
            "Epoch [3/200] Batch [60/113] D_loss: 0.2713, G_loss: 1.7037\n",
            "Epoch [3/200] Batch [70/113] D_loss: 0.3906, G_loss: 1.6229\n",
            "Epoch [3/200] Batch [80/113] D_loss: 0.0997, G_loss: 3.4580\n",
            "Epoch [3/200] Batch [90/113] D_loss: 0.0603, G_loss: 2.9285\n",
            "Epoch [3/200] Batch [100/113] D_loss: 0.1847, G_loss: 1.7122\n",
            "Epoch [3/200] Batch [110/113] D_loss: 0.2387, G_loss: 1.4529\n",
            "Epoch [4/200] Batch [0/113] D_loss: 0.2553, G_loss: 1.4697\n",
            "Epoch [4/200] Batch [10/113] D_loss: 0.3977, G_loss: 3.2984\n",
            "Epoch [4/200] Batch [20/113] D_loss: 0.4156, G_loss: 4.3522\n",
            "Epoch [4/200] Batch [30/113] D_loss: 0.0963, G_loss: 6.3147\n",
            "Epoch [4/200] Batch [40/113] D_loss: 0.2853, G_loss: 2.7914\n",
            "Epoch [4/200] Batch [50/113] D_loss: 0.7187, G_loss: 4.6393\n",
            "Epoch [4/200] Batch [60/113] D_loss: 0.0903, G_loss: 3.1229\n",
            "Epoch [4/200] Batch [70/113] D_loss: 0.2426, G_loss: 4.9894\n",
            "Epoch [4/200] Batch [80/113] D_loss: 0.1360, G_loss: 2.9293\n",
            "Epoch [4/200] Batch [90/113] D_loss: 0.8305, G_loss: 1.9858\n",
            "Epoch [4/200] Batch [100/113] D_loss: 0.5137, G_loss: 3.1747\n",
            "Epoch [4/200] Batch [110/113] D_loss: 1.3263, G_loss: 4.5208\n",
            "Epoch [5/200] Batch [0/113] D_loss: 0.4657, G_loss: 3.2199\n",
            "Epoch [5/200] Batch [10/113] D_loss: 0.0288, G_loss: 7.2758\n",
            "Epoch [5/200] Batch [20/113] D_loss: 0.6152, G_loss: 1.6015\n",
            "Epoch [5/200] Batch [30/113] D_loss: 0.0471, G_loss: 5.2796\n",
            "Epoch [5/200] Batch [40/113] D_loss: 0.4310, G_loss: 2.5695\n",
            "Epoch [5/200] Batch [50/113] D_loss: 0.3113, G_loss: 4.8782\n",
            "Epoch [5/200] Batch [60/113] D_loss: 0.2535, G_loss: 1.8469\n",
            "Epoch [5/200] Batch [70/113] D_loss: 0.2014, G_loss: 2.2179\n",
            "Epoch [5/200] Batch [80/113] D_loss: 0.8611, G_loss: 4.1249\n",
            "Epoch [5/200] Batch [90/113] D_loss: 0.1511, G_loss: 3.9699\n",
            "Epoch [5/200] Batch [100/113] D_loss: 0.4367, G_loss: 1.0978\n",
            "Epoch [5/200] Batch [110/113] D_loss: 0.8228, G_loss: 5.1994\n",
            "Epoch [6/200] Batch [0/113] D_loss: 0.6238, G_loss: 2.5810\n",
            "Epoch [6/200] Batch [10/113] D_loss: 0.0977, G_loss: 3.2571\n",
            "Epoch [6/200] Batch [20/113] D_loss: 0.2504, G_loss: 3.5694\n",
            "Epoch [6/200] Batch [30/113] D_loss: 0.3010, G_loss: 1.7891\n",
            "Epoch [6/200] Batch [40/113] D_loss: 0.1480, G_loss: 5.0214\n",
            "Epoch [6/200] Batch [50/113] D_loss: 0.3512, G_loss: 0.8611\n",
            "Epoch [6/200] Batch [60/113] D_loss: 0.1603, G_loss: 5.4989\n",
            "Epoch [6/200] Batch [70/113] D_loss: 0.1518, G_loss: 2.1235\n",
            "Epoch [6/200] Batch [80/113] D_loss: 0.1905, G_loss: 3.4069\n",
            "Epoch [6/200] Batch [90/113] D_loss: 0.3569, G_loss: 3.6934\n",
            "Epoch [6/200] Batch [100/113] D_loss: 0.1188, G_loss: 2.6212\n",
            "Epoch [6/200] Batch [110/113] D_loss: 0.4653, G_loss: 3.2823\n",
            "Epoch [7/200] Batch [0/113] D_loss: 0.3998, G_loss: 2.3301\n",
            "Epoch [7/200] Batch [10/113] D_loss: 0.6426, G_loss: 5.1713\n",
            "Epoch [7/200] Batch [20/113] D_loss: 0.4612, G_loss: 5.9467\n",
            "Epoch [7/200] Batch [30/113] D_loss: 0.2239, G_loss: 2.9440\n",
            "Epoch [7/200] Batch [40/113] D_loss: 0.1302, G_loss: 3.1348\n",
            "Epoch [7/200] Batch [50/113] D_loss: 0.2060, G_loss: 1.5845\n",
            "Epoch [7/200] Batch [60/113] D_loss: 0.1842, G_loss: 2.5084\n",
            "Epoch [7/200] Batch [70/113] D_loss: 0.0935, G_loss: 3.8498\n",
            "Epoch [7/200] Batch [80/113] D_loss: 0.2704, G_loss: 2.3598\n",
            "Epoch [7/200] Batch [90/113] D_loss: 0.3217, G_loss: 2.6367\n",
            "Epoch [7/200] Batch [100/113] D_loss: 0.5693, G_loss: 1.7924\n",
            "Epoch [7/200] Batch [110/113] D_loss: 0.1821, G_loss: 3.4671\n",
            "Epoch [8/200] Batch [0/113] D_loss: 0.7207, G_loss: 3.4194\n",
            "Epoch [8/200] Batch [10/113] D_loss: 0.3336, G_loss: 3.1013\n",
            "Epoch [8/200] Batch [20/113] D_loss: 0.2263, G_loss: 2.5301\n",
            "Epoch [8/200] Batch [30/113] D_loss: 0.2914, G_loss: 2.5907\n",
            "Epoch [8/200] Batch [40/113] D_loss: 0.1156, G_loss: 4.4675\n",
            "Epoch [8/200] Batch [50/113] D_loss: 0.4683, G_loss: 4.6311\n",
            "Epoch [8/200] Batch [60/113] D_loss: 0.1989, G_loss: 3.2721\n",
            "Epoch [8/200] Batch [70/113] D_loss: 0.1263, G_loss: 3.2145\n",
            "Epoch [8/200] Batch [80/113] D_loss: 0.1674, G_loss: 2.7176\n",
            "Epoch [8/200] Batch [90/113] D_loss: 0.2342, G_loss: 2.1109\n",
            "Epoch [8/200] Batch [100/113] D_loss: 0.1358, G_loss: 3.0160\n",
            "Epoch [8/200] Batch [110/113] D_loss: 0.0730, G_loss: 3.5206\n",
            "Epoch [9/200] Batch [0/113] D_loss: 0.1142, G_loss: 6.7104\n",
            "Epoch [9/200] Batch [10/113] D_loss: 0.0736, G_loss: 3.3327\n",
            "Epoch [9/200] Batch [20/113] D_loss: 0.2430, G_loss: 3.6553\n",
            "Epoch [9/200] Batch [30/113] D_loss: 0.2695, G_loss: 2.0649\n",
            "Epoch [9/200] Batch [40/113] D_loss: 0.1811, G_loss: 3.1935\n",
            "Epoch [9/200] Batch [50/113] D_loss: 0.1673, G_loss: 2.8995\n",
            "Epoch [9/200] Batch [60/113] D_loss: 0.0505, G_loss: 3.6404\n",
            "Epoch [9/200] Batch [70/113] D_loss: 0.3084, G_loss: 4.8224\n",
            "Epoch [9/200] Batch [80/113] D_loss: 0.1868, G_loss: 2.4312\n",
            "Epoch [9/200] Batch [90/113] D_loss: 0.3358, G_loss: 2.3656\n",
            "Epoch [9/200] Batch [100/113] D_loss: 0.2290, G_loss: 2.1186\n",
            "Epoch [9/200] Batch [110/113] D_loss: 0.1446, G_loss: 2.7447\n",
            "Epoch [10/200] Batch [0/113] D_loss: 0.4755, G_loss: 5.0272\n",
            "Epoch [10/200] Batch [10/113] D_loss: 0.2052, G_loss: 2.7873\n",
            "Epoch [10/200] Batch [20/113] D_loss: 0.1487, G_loss: 2.4247\n",
            "Epoch [10/200] Batch [30/113] D_loss: 0.0691, G_loss: 4.1491\n",
            "Epoch [10/200] Batch [40/113] D_loss: 0.0419, G_loss: 4.7624\n",
            "Epoch [10/200] Batch [50/113] D_loss: 0.0626, G_loss: 3.5564\n",
            "Epoch [10/200] Batch [60/113] D_loss: 0.2705, G_loss: 2.9927\n",
            "Epoch [10/200] Batch [70/113] D_loss: 0.2073, G_loss: 1.3272\n",
            "Epoch [10/200] Batch [80/113] D_loss: 0.6197, G_loss: 3.5092\n",
            "Epoch [10/200] Batch [90/113] D_loss: 0.4241, G_loss: 2.5384\n",
            "Epoch [10/200] Batch [100/113] D_loss: 0.5143, G_loss: 3.6529\n",
            "Epoch [10/200] Batch [110/113] D_loss: 0.0447, G_loss: 7.1446\n",
            "Epoch [11/200] Batch [0/113] D_loss: 0.0802, G_loss: 5.3514\n",
            "Epoch [11/200] Batch [10/113] D_loss: 0.2939, G_loss: 3.4251\n",
            "Epoch [11/200] Batch [20/113] D_loss: 0.1774, G_loss: 3.7964\n",
            "Epoch [11/200] Batch [30/113] D_loss: 0.4863, G_loss: 2.2994\n",
            "Epoch [11/200] Batch [40/113] D_loss: 0.1847, G_loss: 2.9685\n",
            "Epoch [11/200] Batch [50/113] D_loss: 0.3285, G_loss: 3.6683\n",
            "Epoch [11/200] Batch [60/113] D_loss: 0.1974, G_loss: 4.9458\n",
            "Epoch [11/200] Batch [70/113] D_loss: 0.2154, G_loss: 5.2220\n",
            "Epoch [11/200] Batch [80/113] D_loss: 0.3287, G_loss: 1.8578\n",
            "Epoch [11/200] Batch [90/113] D_loss: 0.0633, G_loss: 4.9331\n",
            "Epoch [11/200] Batch [100/113] D_loss: 0.0606, G_loss: 3.6140\n",
            "Epoch [11/200] Batch [110/113] D_loss: 1.3428, G_loss: 4.2411\n",
            "Epoch [12/200] Batch [0/113] D_loss: 0.4157, G_loss: 3.3668\n",
            "Epoch [12/200] Batch [10/113] D_loss: 0.1577, G_loss: 3.3190\n",
            "Epoch [12/200] Batch [20/113] D_loss: 0.1055, G_loss: 3.0922\n",
            "Epoch [12/200] Batch [30/113] D_loss: 0.0779, G_loss: 3.4461\n",
            "Epoch [12/200] Batch [40/113] D_loss: 0.0344, G_loss: 5.0781\n",
            "Epoch [12/200] Batch [50/113] D_loss: 0.1413, G_loss: 3.1981\n",
            "Epoch [12/200] Batch [60/113] D_loss: 0.1492, G_loss: 3.7965\n",
            "Epoch [12/200] Batch [70/113] D_loss: 0.1495, G_loss: 2.8181\n",
            "Epoch [12/200] Batch [80/113] D_loss: 0.1671, G_loss: 3.5855\n",
            "Epoch [12/200] Batch [90/113] D_loss: 0.0524, G_loss: 4.7212\n",
            "Epoch [12/200] Batch [100/113] D_loss: 1.2648, G_loss: 5.5245\n",
            "Epoch [12/200] Batch [110/113] D_loss: 0.0711, G_loss: 4.0368\n",
            "Epoch [13/200] Batch [0/113] D_loss: 0.5441, G_loss: 1.0700\n",
            "Epoch [13/200] Batch [10/113] D_loss: 0.1903, G_loss: 3.9537\n",
            "Epoch [13/200] Batch [20/113] D_loss: 0.2332, G_loss: 4.3641\n",
            "Epoch [13/200] Batch [30/113] D_loss: 0.0793, G_loss: 3.4164\n",
            "Epoch [13/200] Batch [40/113] D_loss: 0.0335, G_loss: 3.5925\n",
            "Epoch [13/200] Batch [50/113] D_loss: 0.2419, G_loss: 1.4671\n",
            "Epoch [13/200] Batch [60/113] D_loss: 0.1212, G_loss: 4.6444\n",
            "Epoch [13/200] Batch [70/113] D_loss: 0.0815, G_loss: 2.6803\n",
            "Epoch [13/200] Batch [80/113] D_loss: 0.2089, G_loss: 3.6502\n",
            "Epoch [13/200] Batch [90/113] D_loss: 0.8426, G_loss: 1.9604\n",
            "Epoch [13/200] Batch [100/113] D_loss: 0.1437, G_loss: 4.6449\n",
            "Epoch [13/200] Batch [110/113] D_loss: 0.4604, G_loss: 5.2878\n",
            "Epoch [14/200] Batch [0/113] D_loss: 0.5208, G_loss: 5.6538\n",
            "Epoch [14/200] Batch [10/113] D_loss: 0.3544, G_loss: 0.9890\n",
            "Epoch [14/200] Batch [20/113] D_loss: 0.1074, G_loss: 4.4393\n",
            "Epoch [14/200] Batch [30/113] D_loss: 0.3005, G_loss: 1.3404\n",
            "Epoch [14/200] Batch [40/113] D_loss: 0.3097, G_loss: 2.3204\n",
            "Epoch [14/200] Batch [50/113] D_loss: 0.0911, G_loss: 2.9615\n",
            "Epoch [14/200] Batch [60/113] D_loss: 0.9142, G_loss: 0.8657\n",
            "Epoch [14/200] Batch [70/113] D_loss: 0.0698, G_loss: 5.1278\n",
            "Epoch [14/200] Batch [80/113] D_loss: 0.0220, G_loss: 6.1559\n",
            "Epoch [14/200] Batch [90/113] D_loss: 0.1019, G_loss: 3.1612\n",
            "Epoch [14/200] Batch [100/113] D_loss: 0.1745, G_loss: 3.3001\n",
            "Epoch [14/200] Batch [110/113] D_loss: 0.0555, G_loss: 3.6653\n",
            "Epoch [15/200] Batch [0/113] D_loss: 0.0342, G_loss: 4.3881\n",
            "Epoch [15/200] Batch [10/113] D_loss: 0.0839, G_loss: 2.6820\n",
            "Epoch [15/200] Batch [20/113] D_loss: 0.0703, G_loss: 4.4782\n",
            "Epoch [15/200] Batch [30/113] D_loss: 0.1089, G_loss: 4.2006\n",
            "Epoch [15/200] Batch [40/113] D_loss: 0.2556, G_loss: 3.6086\n",
            "Epoch [15/200] Batch [50/113] D_loss: 0.0678, G_loss: 4.7456\n",
            "Epoch [15/200] Batch [60/113] D_loss: 0.1122, G_loss: 2.0428\n",
            "Epoch [15/200] Batch [70/113] D_loss: 0.5379, G_loss: 0.9286\n",
            "Epoch [15/200] Batch [80/113] D_loss: 0.0218, G_loss: 4.9030\n",
            "Epoch [15/200] Batch [90/113] D_loss: 0.0887, G_loss: 5.7106\n",
            "Epoch [15/200] Batch [100/113] D_loss: 0.0952, G_loss: 3.5036\n",
            "Epoch [15/200] Batch [110/113] D_loss: 0.2095, G_loss: 3.8377\n",
            "Epoch [16/200] Batch [0/113] D_loss: 0.3492, G_loss: 3.7954\n",
            "Epoch [16/200] Batch [10/113] D_loss: 0.0820, G_loss: 4.5691\n",
            "Epoch [16/200] Batch [20/113] D_loss: 0.3803, G_loss: 1.2059\n",
            "Epoch [16/200] Batch [30/113] D_loss: 0.5463, G_loss: 4.2921\n",
            "Epoch [16/200] Batch [40/113] D_loss: 0.0248, G_loss: 5.0295\n",
            "Epoch [16/200] Batch [50/113] D_loss: 0.0362, G_loss: 4.3872\n",
            "Epoch [16/200] Batch [60/113] D_loss: 0.3349, G_loss: 2.2171\n",
            "Epoch [16/200] Batch [70/113] D_loss: 0.3050, G_loss: 2.2520\n",
            "Epoch [16/200] Batch [80/113] D_loss: 0.5239, G_loss: 4.1352\n",
            "Epoch [16/200] Batch [90/113] D_loss: 0.1378, G_loss: 3.6743\n",
            "Epoch [16/200] Batch [100/113] D_loss: 0.5727, G_loss: 1.2266\n",
            "Epoch [16/200] Batch [110/113] D_loss: 0.7018, G_loss: 4.4621\n",
            "Epoch [17/200] Batch [0/113] D_loss: 0.4227, G_loss: 2.4246\n",
            "Epoch [17/200] Batch [10/113] D_loss: 0.2900, G_loss: 3.9707\n",
            "Epoch [17/200] Batch [20/113] D_loss: 0.1381, G_loss: 3.4026\n",
            "Epoch [17/200] Batch [30/113] D_loss: 0.1237, G_loss: 4.6887\n",
            "Epoch [17/200] Batch [40/113] D_loss: 0.5205, G_loss: 4.4130\n",
            "Epoch [17/200] Batch [50/113] D_loss: 0.1423, G_loss: 3.3526\n",
            "Epoch [17/200] Batch [60/113] D_loss: 0.0856, G_loss: 4.6903\n",
            "Epoch [17/200] Batch [70/113] D_loss: 0.2900, G_loss: 3.0390\n",
            "Epoch [17/200] Batch [80/113] D_loss: 0.4969, G_loss: 2.9266\n",
            "Epoch [17/200] Batch [90/113] D_loss: 0.0919, G_loss: 4.3939\n",
            "Epoch [17/200] Batch [100/113] D_loss: 0.1139, G_loss: 3.3537\n",
            "Epoch [17/200] Batch [110/113] D_loss: 0.0758, G_loss: 4.2822\n",
            "Epoch [18/200] Batch [0/113] D_loss: 0.0901, G_loss: 3.9962\n",
            "Epoch [18/200] Batch [10/113] D_loss: 0.1535, G_loss: 2.3845\n",
            "Epoch [18/200] Batch [20/113] D_loss: 0.1107, G_loss: 5.3544\n",
            "Epoch [18/200] Batch [30/113] D_loss: 0.1594, G_loss: 2.1714\n",
            "Epoch [18/200] Batch [40/113] D_loss: 0.4028, G_loss: 3.9278\n",
            "Epoch [18/200] Batch [50/113] D_loss: 0.1473, G_loss: 3.3799\n",
            "Epoch [18/200] Batch [60/113] D_loss: 0.2003, G_loss: 3.0219\n",
            "Epoch [18/200] Batch [70/113] D_loss: 0.1575, G_loss: 2.7391\n",
            "Epoch [18/200] Batch [80/113] D_loss: 0.4133, G_loss: 0.5747\n",
            "Epoch [18/200] Batch [90/113] D_loss: 0.1567, G_loss: 3.5802\n",
            "Epoch [18/200] Batch [100/113] D_loss: 0.1435, G_loss: 2.6900\n",
            "Epoch [18/200] Batch [110/113] D_loss: 0.1899, G_loss: 4.8450\n",
            "Epoch [19/200] Batch [0/113] D_loss: 0.1900, G_loss: 4.8513\n",
            "Epoch [19/200] Batch [10/113] D_loss: 0.1579, G_loss: 3.3159\n",
            "Epoch [19/200] Batch [20/113] D_loss: 0.0728, G_loss: 3.6113\n",
            "Epoch [19/200] Batch [30/113] D_loss: 0.0423, G_loss: 3.0343\n",
            "Epoch [19/200] Batch [40/113] D_loss: 0.0574, G_loss: 5.3262\n",
            "Epoch [19/200] Batch [50/113] D_loss: 0.1909, G_loss: 2.5075\n",
            "Epoch [19/200] Batch [60/113] D_loss: 0.1052, G_loss: 4.6960\n",
            "Epoch [19/200] Batch [70/113] D_loss: 0.3809, G_loss: 2.1595\n",
            "Epoch [19/200] Batch [80/113] D_loss: 0.0741, G_loss: 3.3296\n",
            "Epoch [19/200] Batch [90/113] D_loss: 0.1675, G_loss: 1.4135\n",
            "Epoch [19/200] Batch [100/113] D_loss: 0.0948, G_loss: 3.8989\n",
            "Epoch [19/200] Batch [110/113] D_loss: 0.1332, G_loss: 4.7872\n",
            "Epoch [20/200] Batch [0/113] D_loss: 0.1148, G_loss: 4.8279\n",
            "Epoch [20/200] Batch [10/113] D_loss: 0.0911, G_loss: 3.5304\n",
            "Epoch [20/200] Batch [20/113] D_loss: 0.0917, G_loss: 6.1181\n",
            "Epoch [20/200] Batch [30/113] D_loss: 0.0369, G_loss: 6.2946\n",
            "Epoch [20/200] Batch [40/113] D_loss: 0.2882, G_loss: 2.6268\n",
            "Epoch [20/200] Batch [50/113] D_loss: 0.4349, G_loss: 1.1043\n",
            "Epoch [20/200] Batch [60/113] D_loss: 0.1925, G_loss: 3.1533\n",
            "Epoch [20/200] Batch [70/113] D_loss: 0.2796, G_loss: 2.9980\n",
            "Epoch [20/200] Batch [80/113] D_loss: 0.1730, G_loss: 3.5604\n",
            "Epoch [20/200] Batch [90/113] D_loss: 0.0560, G_loss: 4.1195\n",
            "Epoch [20/200] Batch [100/113] D_loss: 0.0512, G_loss: 4.9107\n",
            "Epoch [20/200] Batch [110/113] D_loss: 0.0510, G_loss: 11.7256\n",
            "Epoch [21/200] Batch [0/113] D_loss: 0.1015, G_loss: 3.0568\n",
            "Epoch [21/200] Batch [10/113] D_loss: 0.1397, G_loss: 3.7602\n",
            "Epoch [21/200] Batch [20/113] D_loss: 0.2401, G_loss: 3.5308\n",
            "Epoch [21/200] Batch [30/113] D_loss: 0.2083, G_loss: 3.1173\n",
            "Epoch [21/200] Batch [40/113] D_loss: 0.1090, G_loss: 3.4822\n",
            "Epoch [21/200] Batch [50/113] D_loss: 0.1467, G_loss: 2.4998\n",
            "Epoch [21/200] Batch [60/113] D_loss: 0.2035, G_loss: 3.9517\n",
            "Epoch [21/200] Batch [70/113] D_loss: 0.1349, G_loss: 3.5535\n",
            "Epoch [21/200] Batch [80/113] D_loss: 0.2373, G_loss: 2.3480\n",
            "Epoch [21/200] Batch [90/113] D_loss: 0.1673, G_loss: 4.1763\n",
            "Epoch [21/200] Batch [100/113] D_loss: 0.1423, G_loss: 3.1156\n",
            "Epoch [21/200] Batch [110/113] D_loss: 0.4592, G_loss: 2.2738\n",
            "Epoch [22/200] Batch [0/113] D_loss: 0.0999, G_loss: 5.2107\n",
            "Epoch [22/200] Batch [10/113] D_loss: 0.1537, G_loss: 2.2248\n",
            "Epoch [22/200] Batch [20/113] D_loss: 0.3222, G_loss: 3.5765\n",
            "Epoch [22/200] Batch [30/113] D_loss: 0.2007, G_loss: 4.1005\n",
            "Epoch [22/200] Batch [40/113] D_loss: 0.1141, G_loss: 5.3407\n",
            "Epoch [22/200] Batch [50/113] D_loss: 0.1592, G_loss: 5.4229\n",
            "Epoch [22/200] Batch [60/113] D_loss: 0.0405, G_loss: 5.3852\n",
            "Epoch [22/200] Batch [70/113] D_loss: 0.1625, G_loss: 2.5187\n",
            "Epoch [22/200] Batch [80/113] D_loss: 0.0432, G_loss: 5.7199\n",
            "Epoch [22/200] Batch [90/113] D_loss: 0.0568, G_loss: 2.7628\n",
            "Epoch [22/200] Batch [100/113] D_loss: 0.3094, G_loss: 3.4732\n",
            "Epoch [22/200] Batch [110/113] D_loss: 0.1435, G_loss: 3.9031\n",
            "Epoch [23/200] Batch [0/113] D_loss: 0.7493, G_loss: 5.2123\n",
            "Epoch [23/200] Batch [10/113] D_loss: 0.2698, G_loss: 3.7617\n",
            "Epoch [23/200] Batch [20/113] D_loss: 0.1341, G_loss: 2.9484\n",
            "Epoch [23/200] Batch [30/113] D_loss: 0.1335, G_loss: 3.8895\n",
            "Epoch [23/200] Batch [40/113] D_loss: 0.1374, G_loss: 3.8078\n",
            "Epoch [23/200] Batch [50/113] D_loss: 0.5995, G_loss: 0.6906\n",
            "Epoch [23/200] Batch [60/113] D_loss: 0.1512, G_loss: 2.2534\n",
            "Epoch [23/200] Batch [70/113] D_loss: 0.0189, G_loss: 5.2711\n",
            "Epoch [23/200] Batch [80/113] D_loss: 0.0473, G_loss: 3.7174\n",
            "Epoch [23/200] Batch [90/113] D_loss: 0.0232, G_loss: 4.7121\n",
            "Epoch [23/200] Batch [100/113] D_loss: 0.0506, G_loss: 4.0667\n",
            "Epoch [23/200] Batch [110/113] D_loss: 0.0986, G_loss: 3.2540\n",
            "Epoch [24/200] Batch [0/113] D_loss: 0.2809, G_loss: 2.0881\n",
            "Epoch [24/200] Batch [10/113] D_loss: 0.2005, G_loss: 2.8376\n",
            "Epoch [24/200] Batch [20/113] D_loss: 0.1750, G_loss: 5.0223\n",
            "Epoch [24/200] Batch [30/113] D_loss: 0.1042, G_loss: 3.1846\n",
            "Epoch [24/200] Batch [40/113] D_loss: 0.5097, G_loss: 1.0259\n",
            "Epoch [24/200] Batch [50/113] D_loss: 0.3984, G_loss: 1.9414\n",
            "Epoch [24/200] Batch [60/113] D_loss: 0.2420, G_loss: 3.4125\n",
            "Epoch [24/200] Batch [70/113] D_loss: 0.1019, G_loss: 4.6026\n",
            "Epoch [24/200] Batch [80/113] D_loss: 0.0947, G_loss: 3.4710\n",
            "Epoch [24/200] Batch [90/113] D_loss: 0.1789, G_loss: 3.5092\n",
            "Epoch [24/200] Batch [100/113] D_loss: 0.0760, G_loss: 4.8975\n",
            "Epoch [24/200] Batch [110/113] D_loss: 0.1552, G_loss: 3.5238\n",
            "Epoch [25/200] Batch [0/113] D_loss: 0.0455, G_loss: 4.5067\n",
            "Epoch [25/200] Batch [10/113] D_loss: 0.0775, G_loss: 3.4841\n",
            "Epoch [25/200] Batch [20/113] D_loss: 0.0528, G_loss: 3.3747\n",
            "Epoch [25/200] Batch [30/113] D_loss: 0.0818, G_loss: 5.5051\n",
            "Epoch [25/200] Batch [40/113] D_loss: 0.1514, G_loss: 3.4700\n",
            "Epoch [25/200] Batch [50/113] D_loss: 0.3082, G_loss: 3.9941\n",
            "Epoch [25/200] Batch [60/113] D_loss: 0.0466, G_loss: 5.7868\n",
            "Epoch [25/200] Batch [70/113] D_loss: 0.1554, G_loss: 3.3073\n",
            "Epoch [25/200] Batch [80/113] D_loss: 0.1106, G_loss: 3.1996\n",
            "Epoch [25/200] Batch [90/113] D_loss: 0.5880, G_loss: 2.7986\n",
            "Epoch [25/200] Batch [100/113] D_loss: 0.0751, G_loss: 3.6471\n",
            "Epoch [25/200] Batch [110/113] D_loss: 0.1964, G_loss: 3.6445\n",
            "Epoch [26/200] Batch [0/113] D_loss: 0.1117, G_loss: 3.5733\n",
            "Epoch [26/200] Batch [10/113] D_loss: 1.3510, G_loss: 0.8326\n",
            "Epoch [26/200] Batch [20/113] D_loss: 0.2801, G_loss: 5.2464\n",
            "Epoch [26/200] Batch [30/113] D_loss: 0.2182, G_loss: 3.7117\n",
            "Epoch [26/200] Batch [40/113] D_loss: 0.0852, G_loss: 2.8260\n",
            "Epoch [26/200] Batch [50/113] D_loss: 0.2165, G_loss: 4.0036\n",
            "Epoch [26/200] Batch [60/113] D_loss: 0.7732, G_loss: 0.8447\n",
            "Epoch [26/200] Batch [70/113] D_loss: 0.0553, G_loss: 2.8675\n",
            "Epoch [26/200] Batch [80/113] D_loss: 0.1398, G_loss: 3.5847\n",
            "Epoch [26/200] Batch [90/113] D_loss: 0.3190, G_loss: 3.1505\n",
            "Epoch [26/200] Batch [100/113] D_loss: 0.1402, G_loss: 4.2048\n",
            "Epoch [26/200] Batch [110/113] D_loss: 0.1006, G_loss: 4.4936\n",
            "Epoch [27/200] Batch [0/113] D_loss: 0.1823, G_loss: 2.6725\n",
            "Epoch [27/200] Batch [10/113] D_loss: 0.1175, G_loss: 5.7044\n",
            "Epoch [27/200] Batch [20/113] D_loss: 0.1174, G_loss: 3.8811\n",
            "Epoch [27/200] Batch [30/113] D_loss: 0.1033, G_loss: 4.9757\n",
            "Epoch [27/200] Batch [40/113] D_loss: 0.1140, G_loss: 4.9594\n"
          ]
        }
      ],
      "execution_count": null
    }
  ]
}